# Домашнее задание к занятию "`Введение в мониторинг`" - `Исаенков Евгений`

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. 
Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?
2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?
3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. 
Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

## Дополнительное задание* (со звёздочкой) 

Выполнение этого задания необязательно и никак не влияет на получение зачёта по домашней работе.

_____

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. 

Вы, как опытный системный администратор, знаете, что системная информация сервера лежит в директории `/proc`. Также знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав всё, вы спроектировали приложение, которое:

- является python3-скриптом;
- собирает метрики из папки `/proc`;
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY — год, MM — месяц, DD — день);
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp — временная метка, int, unixtimestamp;
  + metric_1 — метрика 1;
  + metric_2 — метрика 2;
  
     ...
     
  + metric_N — метрика N.
  
- сбор метрик происходит каждую минуту по cron-расписанию.

Для успешного выполнения задания нужно привести:
* работающий код python3-скрипта;
* конфигурацию cron-расписания;
* пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не меньше пяти записей.

Дополнительная информация:
1. Количество собираемых метрик должно быть не меньше четырёх.
2. По желанию можно не ограничивать себя только сбором метрик из `/proc`.

---

## Ответ

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

- CPU Usage – чтобы отслеживать нагрузку на процессор, который активно используется вычислениями. Если нагрузка слишком высока, это может привести к снижению производительности или полной остановке вычислений.
- Memory Usage – для мониторинга использования оперативной памяти, так как её нехватка может вызвать сбои или замедление в выполнении вычислений, особенно если объём данных очень большой.
- Disk Usage – необходимо контролировать использование дискового пространства, чтобы не допустить его переполнения, так как отчеты сохраняются на диск. Переполненный диск может привести к ошибкам записи и потере данных.
- Network Traffic – важно отслеживать сетевой трафик, так как взаимодействие с платформой происходит по HTTP. Увеличение трафика может сигнализировать о потенциальных проблемах с сетью или атаках на сервер.
- HTTP Response Time – для контроля времени отклика сервера. Высокое время отклика может указывать на проблемы с производительностью сервера или недостаток ресурсов.
- Error Rates – мониторинг ошибок HTTP-запросов позволяет выявлять проблемы в работе платформы, такие как некорректные запросы или сбои в обработке данных.

2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

Я бы предложил следующие метрики, которые напрямую связаны с качеством обслуживания и выполнением обязательств перед клиентами:

- Время отклика сервиса – это время, которое требуется платформе для ответа на запросы клиентов. Чем меньше время отклика, тем выше удовлетворенность клиентов, так как они быстрее получают свои результаты.
- Процент успешных запросов – доля запросов, которые были обработаны без ошибок. Эта метрика показывает стабильность работы сервиса и помогает убедиться, что он выполняет свои функции без сбоев.
- Время простоя – количество времени, когда платформа была недоступна. Чем меньше времени простоя, тем лучше выполняются наши обязательства перед клиентами. Длительные простои негативно влияют на качество обслуживания.
- Обратная связь от клиентов – можно внедрить сбор данных о том, как пользователи оценивают работу сервиса, их уровень удовлетворенности, а также собирать жалобы и предложения. Это поможет понять, насколько мы справляемся с их ожиданиями.

3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

В условиях отсутствия бюджета можно использовать следующие подходы:

- Локальное хранение логов: Если приложение уже генерирует логи, их можно сохранять локально на сервере. Разработчики могут получить доступ к этим логам через SSH или другие удаленные методы, чтобы просматривать ошибки.
- Бесплатные инструменты для сбора логов: Использование инструментов, таких как Fluentd или Logstash, которые можно настроить для сбора и агрегации логов без значительных финансовых затрат. Они могут отправлять логи в централизованное хранилище.
- Использование бесплатных платформ для визуализации: Такие инструменты, как Grafana или Kibana, можно настроить для визуализации логов и ошибок. Они бесплатны и предоставляют удобные интерфейсы для анализа данных.
- Cron-сценарии для уведомлений: Можно настроить cron-задания, которые будут периодически собирать ошибки из логов и отправлять их разработчикам на электронную почту или в мессенджеры.

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. 
Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

- Ошибка заключается в том, что формула summ_2xx_requests/summ_all_requests учитывает только успешные запросы с кодами 2xx. Однако, в HTTP также есть коды 3xx (перенаправления), которые не являются ошибками и считаются успешными. Если коды 4xx и 5xx отсутствуют, то оставшиеся 30% запросов, скорее всего, это коды 3xx. Их нужно также учитывать в расчёте успешных запросов, чтобы точно отобразить реальный процент выполнения SLA.


### Необязательное задание

Для сбора метрик был создан следующий скрипт, который позволяет собирать информацию о памяти, процессоре, процессах, времени работы системы, дисковом пространстве, сетевых соединениях и температуре CPU (если доступно). Собранные метрики записываются в файл в формате JSON.
Для удобства чтения кода и работы с метриками были созданы отдельные функции для сбора каждой категории метрик. Каждая из функций дополнительно документирована комментариями.
При необходимости можно выборочно отключать не требуемые функции сбора метрик.
Так же, для сбора метрик, импортируется не стандартная библиотека psutil. Она используется для получения информации о дисковом пространстве, сетевых соединениях и температуре CPU.

```python
import json
import os
import time
from datetime import datetime
import psutil

# Функция для чтения метрики из /proc/meminfo (используемая память)
def get_memory_info():
    with open('/proc/meminfo', 'r') as f:
        meminfo = f.readlines()
    mem_total = int(meminfo[0].split()[1])  # Общее количество памяти
    mem_free = int(meminfo[1].split()[1])   # Свободная память
    mem_available = int(meminfo[2].split()[1])  # Доступная память
    return {'mem_total': mem_total, 'mem_free': mem_free, 'mem_available': mem_available}

# Функция для чтения загрузки процессора из /proc/loadavg
def get_cpu_load():
    with open('/proc/loadavg', 'r') as f:
        loadavg = f.read().split()
    return {'cpu_load_1min': float(loadavg[0]), 'cpu_load_5min': float(loadavg[1]), 'cpu_load_15min': float(loadavg[2])}

# Функция для чтения информации о процессах
def get_process_info():
    with open('/proc/stat', 'r') as f:
        lines = f.readlines()
    process_count = 0
    for line in lines:
        if line.startswith('processes'):
            process_count = int(line.split()[1])
            break
    return {'process_count': process_count}

# Функция для чтения информации о времени работы системы
def get_uptime():
    with open('/proc/uptime', 'r') as f:
        uptime_seconds = float(f.read().split()[0])
    return {'uptime_seconds': uptime_seconds}

# Функция для получения информации о дисковом пространстве
def get_disk_usage():
    disk_usage = psutil.disk_usage('/')
    return {
        'disk_total': disk_usage.total // (1024 * 1024),  # MB
        'disk_used': disk_usage.used // (1024 * 1024),    # MB
        'disk_free': disk_usage.free // (1024 * 1024),    # MB
        'disk_percent': disk_usage.percent                # Процент использованного пространства
    }

# Функция для получения количества активных сетевых соединений
def get_network_connections():
    return {'active_connections': len(psutil.net_connections())}

# Функция для получения информации о температуре CPU. Т.к. температура CPU не всегда доступна, особенно при работе с VM, обрабатываем исключение
def get_cpu_temperature():
    try:
        temps = psutil.sensors_temperatures()
        if "coretemp" in temps:
            return {'cpu_temperature': temps['coretemp'][0].current}
        else:
            return {'cpu_temperature': 'N/A'}
    except AttributeError:
        return {'cpu_temperature': 'N/A'}

# Основная функция сбора метрик
def collect_metrics():
    timestamp = int(time.time())
    metrics = {'timestamp': timestamp}
    metrics.update(get_memory_info())
    metrics.update(get_cpu_load())
    metrics.update(get_process_info())
    metrics.update(get_uptime())
    metrics.update(get_disk_usage())
    metrics.update(get_network_connections())
    metrics.update(get_cpu_temperature())
    
    # Формируем название файла с логами
    log_filename = datetime.now().strftime('/var/log/%Y-%m-%d-awesome-monitoring.log')
    
    # Записываем метрики в файл в формате JSON
    with open(log_filename, 'a') as log_file:
        log_file.write(json.dumps(metrics) + '\n')

if __name__ == '__main__':
    collect_metrics()
```

Для запуска скрипта каждую минуту по cron-расписанию необходимо добавить задачу в cron. Для этого выполним команду `crontab -e` и добавим следующую строку:

```bash
root@vm1:~# crontab -l
# Edit this file to introduce tasks to be run by cron.
#
# Each task to run has to be defined through a single line
# indicating with different fields when the task will be run
# and what command to run for the task
#
# To define the time you can provide concrete values for
# minute (m), hour (h), day of month (dom), month (mon),
# and day of week (dow) or use '*' in these fields (for 'any').
#
# Notice that tasks will be started based on the cron's system
# daemon's notion of time and timezones.
#
# Output of the crontab jobs (including errors) is sent through
# email to the user the crontab file belongs to (unless redirected).
#
# For example, you can run a backup of all your user accounts
# at 5 a.m every week with:
# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/
#
# For more information see the manual pages of crontab(5) and cron(8)
#
# m h  dom mon dow   command
* * * * * /usr/bin/python3 /home/udjin/collector.py
```

После этого скрипт будет запускаться каждую минуту и собирать метрики в файл логов в формате JSON. Пример файла логов:

```bash
$ cat /var/log/2024-09-20-awesome-monitoring.log
{"timestamp": 1726817669, "mem_total": 2015112, "mem_free": 326092, "mem_available": 1611480, "cpu_load_1min": 0.16, "cpu_load_5min": 0.48, "cpu_load_15min": 0.35, "process_count": 16270, "uptime_seconds": 838.03, "disk_total": 11483, "disk_used": 6836, "disk_free": 4041, "disk_percent": 62.8, "active_connections": 8, "cpu_temperature": "N/A"}
{"timestamp": 1726817819, "mem_total": 2015112, "mem_free": 336004, "mem_available": 1623392, "cpu_load_1min": 0.08, "cpu_load_5min": 0.31, "cpu_load_15min": 0.31, "process_count": 16310, "uptime_seconds": 987.63, "disk_total": 11483, "disk_used": 6836, "disk_free": 4041, "disk_percent": 62.8, "active_connections": 7, "cpu_temperature": "N/A"}
{"timestamp": 1726817881, "mem_total": 2015112, "mem_free": 335752, "mem_available": 1623212, "cpu_load_1min": 0.02, "cpu_load_5min": 0.25, "cpu_load_15min": 0.28, "process_count": 16332, "uptime_seconds": 1050.47, "disk_total": 11483, "disk_used": 6836, "disk_free": 4041, "disk_percent": 62.8, "active_connections": 7, "cpu_temperature": "N/A"}
{"timestamp": 1726817942, "mem_total": 2015112, "mem_free": 335752, "mem_available": 1623280, "cpu_load_1min": 0.01, "cpu_load_5min": 0.2, "cpu_load_15min": 0.26, "process_count": 16341, "uptime_seconds": 1110.56, "disk_total": 11483, "disk_used": 6836, "disk_free": 4041, "disk_percent": 62.8, "active_connections": 7, "cpu_temperature": "N/A"}
{"timestamp": 1726818001, "mem_total": 2015112, "mem_free": 174756, "mem_available": 1599648, "cpu_load_1min": 0.06, "cpu_load_5min": 0.18, "cpu_load_15min": 0.25, "process_count": 16375, "uptime_seconds": 1169.63, "disk_total": 11483, "disk_used": 6967, "disk_free": 3911, "disk_percent": 64.0, "active_connections": 8, "cpu_temperature": "N/A"}
{"timestamp": 1726818061, "mem_total": 2015112, "mem_free": 89968, "mem_available": 1561868, "cpu_load_1min": 0.61, "cpu_load_5min": 0.29, "cpu_load_15min": 0.28, "process_count": 16877, "uptime_seconds": 1229.81, "disk_total": 11483, "disk_used": 7175, "disk_free": 3703, "disk_percent": 66.0, "active_connections": 8, "cpu_temperature": "N/A"}
{"timestamp": 1726818121, "mem_total": 2015112, "mem_free": 123640, "mem_available": 1548504, "cpu_load_1min": 1.7, "cpu_load_5min": 0.64, "cpu_load_15min": 0.4, "process_count": 20168, "uptime_seconds": 1289.96, "disk_total": 11483, "disk_used": 7209, "disk_free": 3669, "disk_percent": 66.3, "active_connections": 7, "cpu_temperature": "N/A"}
{"timestamp": 1726818181, "mem_total": 2015112, "mem_free": 91376, "mem_available": 1564980, "cpu_load_1min": 1.68, "cpu_load_5min": 0.83, "cpu_load_15min": 0.49, "process_count": 26414, "uptime_seconds": 1350.04, "disk_total": 11483, "disk_used": 7274, "disk_free": 3603, "disk_percent": 66.9, "active_connections": 7, "cpu_temperature": "N/A"}
```