# Домашнее задание к занятию "`Инцидент-менеджмент`" - `Исаенков Евгений`

## Задание

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информацию о сбое можно изучить по ссылкам ниже:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

---

## Ответ

# Постмортем: Сбой системы GitHub 21-22 октября 2018 года

## Краткое описание инцидента

21 октября 2018 года в 22:52 UTC на платформе GitHub произошёл инцидент, приведший к деградации сервисов на 24 часа и 11 минут. Хотя некоторые части платформы не были затронуты, множество внутренних систем испытывало проблемы, что приводило к отображению устаревшей и некорректной информации. В течение большей части инцидента GitHub также не мог отправлять вебхуки или собирать и публиковать сайты GitHub Pages.

## Предшествующие события

- Проводились плановые работы по замене вышедшего из строя оптического оборудования 100G в сетевом узле на Восточном побережье США.

## Причина инцидента

- Кратковременная потеря соединения между сетевым хабом Восточного побережья и основным центром обработки данных (ЦОД) на Восточном побережье.
- Соединение было восстановлено через 43 секунды, но эта краткая потеря связи запустила цепочку событий, приведшую к 24 часам и 11 минутам деградации сервисов.
- Система управления базами данных MySQL начала некорректно переключать первичные узлы между ЦОД на Восточном и Западном побережьях из-за изменений в топологии, вызванных сбоем соединения.

## Воздействие

- **Отображение устаревшей или некорректной информации**: Пользователи видели несоответствующие данные в интерфейсе GitHub.
- **Невозможность обработки вебхуков и сборки GitHub Pages**: В течение инцидента платформа не могла обрабатывать эти задачи.
- **Замедленная работа некоторых функций**: Из-за задержек в репликации данных некоторые сервисы работали медленнее обычного.
- **Ручная сверка данных**: Потребовалась ручная проверка нескольких секунд записей в базе данных для обеспечения их целостности.

## Обнаружение

- **22:54 UTC**: Внутренние системы мониторинга начали генерировать множественные предупреждения о сбоях.
- Несколько инженеров сразу же начали реагировать и проводить анализ поступающих уведомлений.

## Реакция

- **23:02 UTC**: Инженеры команды быстрого реагирования обнаружили, что топология нескольких кластеров баз данных находится в нестандартном состоянии.
- **23:07 UTC**: Было принято решение вручную заблокировать внутренние инструменты деплоя, чтобы предотвратить внесение дополнительных изменений.
- **23:09 UTC**: Сайт переведён в жёлтый статус, что автоматически эскалировало ситуацию до активного инцидента и оповестило координатора.
- **23:11 UTC**: Координатор инцидента присоединился и через две минуты изменил статус на красный.
- **23:13 UTC**: Были привлечены дополнительные инженеры из команды по работе с базами данных для детального анализа ситуации.
- **23:19 UTC**: Принято решение остановить задачи, записывающие метаданные (например, пуши), чтобы предотвратить дальнейшую рассинхронизацию данных.

## Восстановление

- **00:05 UTC**: Начата разработка плана по разрешению несоответствий данных и реализации процедур переключения баз данных MySQL.
- **00:41 UTC**: Запущен процесс восстановления всех затронутых кластеров из резервных копий.
- **06:51 UTC**: Несколько кластеров завершили восстановление в ЦОД на Восточном побережье и начали репликацию новых данных с Западного побережья.
- **11:12 UTC**: Первичные базы данных для всех кластеров снова установлены в ЦОД на Восточном побережье, что значительно улучшило производительность сайта.
- **13:15 UTC**: Добавлены дополнительные реплики MySQL в публичном облаке на Восточном побережье для ускорения чтения и уменьшения задержек.
- **16:24 UTC**: После синхронизации реплик проведено переключение обратно на первоначальную топологию, что решило проблемы с задержками и доступностью.
- **16:45 UTC**: Начато восстановление обработки накопившихся задач, таких как вебхуки и сборка сайтов.
- **23:03 UTC**: Все отложенные вебхуки и сборки GitHub Pages обработаны; подтверждена целостность и корректная работа всех систем. Статус сайта обновлён на зелёный.

## Таймлайн

- **22:52 21.10.2018 UTC**: Потеря соединения между сетевым хабом и основным ЦОД на Восточном побережье.
- **22:54 UTC**: Обнаружение сбоя системами мониторинга.
- **23:02 UTC**: Выявлено неожиданное состояние топологии баз данных.
- **23:07 UTC**: Блокировка инструментов деплоя.
- **23:09 UTC**: Присвоение инциденту жёлтого статуса.
- **23:11 UTC**: Повышение статуса до красного.
- **23:13 UTC**: Привлечение дополнительных инженеров для анализа.
- **23:19 UTC**: Остановка задач записи метаданных.
- **00:05 22.10.2018 UTC**: Разработка плана восстановления.
- **00:41 UTC**: Начало восстановления кластеров из резервных копий.
- **06:51 UTC**: Завершение восстановления и начало репликации данных.
- **07:46 UTC**: Публикация сообщения об инциденте в официальном блоге.
- **11:12 UTC**: Первичные базы данных установлены в ЦОД на Восточном побережье.
- **13:15 UTC**: Добавление дополнительных реплик MySQL.
- **16:24 UTC**: Переключение обратно на первоначальную топологию.
- **16:45 UTC**: Начало обработки накопившихся задач.
- **23:03 UTC**: Завершение обработки всех задач; статус сайта обновлён на зелёный.

## Последующие действия

- **Разрешение несоответствий данных**: Сохранены бинарные логи MySQL с записями, не реплицированными на Западное побережье. Проводится анализ для автоматического восстановления этих записей или обращения к пользователям при необходимости.
- **Изменение настроек Orchestrator**: Обновлена конфигурация Orchestrator для предотвращения повышения первичных баз данных через региональные границы, чтобы избежать подобной ситуации в будущем.
- **Ускорение перехода на новый механизм отчётов статуса**: Ускорена миграция на новую систему отчётности, позволяющую предоставлять более подробную информацию о состоянии сервисов.
- **Инфраструктурные инициативы**: Ускорена работа над проектом по поддержке обслуживания трафика из нескольких ЦОД в активной/активной/активной архитектуре с резервированием N+1.
- **Тестирование негативных сценариев**: Внедрена практика проактивного тестирования отказов и негативных сценариев для повышения устойчивости системы.

## Выводы и рекомендации

Инцидент показал необходимость улучшения отказоустойчивости и готовности системы к кратковременным сбоям связи. Рекомендуется:

- **Улучшить конфигурацию систем управления базами данных**: Настроить Orchestrator таким образом, чтобы избежать некорректных переключений первичных узлов между регионами.
- **Повысить отказоустойчивость инфраструктуры**: Ускорить внедрение активной/активной/активной архитектуры для обеспечения непрерывной работы при сбое одного из ЦОД.
- **Оптимизировать процессы восстановления**: Улучшить процедуры восстановления из резервных копий для сокращения времени простоя.
- **Улучшить коммуникацию**: Разработать новые механизмы отчётности для предоставления более точной и своевременной информации пользователям во время инцидентов.
- **Внедрить практики тестирования отказов**: Создать инструменты для регулярного тестирования устойчивости системы к различным отказам и сбоям.
